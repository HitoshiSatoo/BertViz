# BertViz - Visualização do Transformer

## Descrição
Este projeto tem como objetivo estudar e visualizar a estrutura do Transformer, com foco no Encoder. Ele explora os principais componentes do modelo, incluindo o mecanismo de **Multi-Head Self-Attention** e a rede **Feed-Forward**, fundamentais para o funcionamento do Transformer.

## Estrutura do Notebook
O notebook apresenta:
- Explicação teórica sobre o Encoder do Transformer.
- Visualização das atenções em diferentes camadas.
- Exemplos práticos utilizando modelos baseados em Transformer, como o BERT.

## Requisitos
Antes de executar o notebook, certifique-se de ter as seguintes dependências instaladas:

```bash
pip install torch transformers matplotlib seaborn
```

## Como Executar
1. Clone este repositório:
   ```bash
   git clone https://github.com/HitoshiSatoo/BertViz.git
   ```
2. Acesse o diretório do projeto:
   ```bash
   cd BertViz
   ```
3. Abra o notebook Jupyter:
   ```bash
   jupyter notebook BertViz.ipynb
   ```

## Referências
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)

## Autor
Desenvolvido por Victor Hitoshi Sato.

